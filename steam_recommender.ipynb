{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-ERfVZOz-R2r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-ERfVZOz-R2r",
    "outputId": "9aba2530-7012-4524-e062-42a22975ab04"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbeffd8a",
   "metadata": {
    "id": "cbeffd8a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "UBABE59G-XH-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBABE59G-XH-",
    "outputId": "ee2f8c25-e236-43ef-a085-a2754860b7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "CJagRfZ29fvS",
   "metadata": {
    "id": "CJagRfZ29fvS"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/steam-200k.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f0209",
   "metadata": {
    "id": "0b9f0209"
   },
   "outputs": [],
   "source": [
    "# use at jupyter notebook\n",
    "data = pd.read_csv('data/steam-200k.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c770bb",
   "metadata": {
    "id": "a7c770bb"
   },
   "outputs": [],
   "source": [
    "# delete unnecessary data\n",
    "data = data.drop([4],axis=1)\n",
    "data.columns = ['userid','gametitle','behaviour','value']\n",
    "\n",
    "# group by purchase and play\n",
    "behv = data.groupby('behaviour')\n",
    "\n",
    "purc = behv.get_group('purchase')\n",
    "ply = behv.get_group('play')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f691c",
   "metadata": {
    "id": "e54f691c"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pt0K1o37nm0-",
   "metadata": {
    "id": "pt0K1o37nm0-"
   },
   "source": [
    "After we split the data into Purchasing and Playing part, now it is time for us to do data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9689defa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9689defa",
    "outputId": "ef9175c4-3e05-4910-c91e-a96c575f0368"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# counts total number of games being purchased by the users\n",
    "purc['counts'] = purc.groupby('gametitle')['gametitle'].transform('size')\n",
    "\n",
    "# use MinMaxScaler to scale the number of purchases into ratings, in scale of 1-5\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "ori_purc_count = purc['counts'].values.reshape(-1,1)\n",
    "scalar = MinMaxScaler(feature_range=(1,5))\n",
    "purc_count_trans = scalar.fit_transform(ori_purc_count)\n",
    "\n",
    "purc['counts_trans'] = purc_count_trans\n",
    "\n",
    "# round up functions here\n",
    "import math\n",
    "\n",
    "def roundup(n):\n",
    "    if n - math.floor(n) < 0.5:\n",
    "        return math.floor(n)\n",
    "    return math.ceil(n)\n",
    "\n",
    "# round the ratings to the nearest integer\n",
    "purc['counts_trans'] = purc.counts_trans.apply(lambda n:roundup(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vHxo_BvU-vLk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHxo_BvU-vLk",
    "outputId": "695f8bb6-f639-40e2-98a8-6ad843abe0bf"
   },
   "outputs": [],
   "source": [
    "# next we install surprise library\n",
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "942b2be5",
   "metadata": {
    "id": "942b2be5"
   },
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "reader = Reader(rating_scale = (1.0,5.0))\n",
    "data_purc = Dataset.load_from_df(purc[['userid','gametitle','counts_trans']],reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368af3e7",
   "metadata": {
    "id": "368af3e7"
   },
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6lV6man4oPNr",
   "metadata": {
    "id": "6lV6man4oPNr"
   },
   "source": [
    "Now we training the purchasing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "492dbe98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "492dbe98",
    "outputId": "f7dc2c97-4127-43ef-9c2d-41309ec336b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (10.149754047393799,\n",
       "  10.31432056427002,\n",
       "  10.193566799163818,\n",
       "  10.186446189880371,\n",
       "  10.389919519424438),\n",
       " 'test_mae': array([0.03307733, 0.03318721, 0.03327754, 0.03366263, 0.03362549]),\n",
       " 'test_rmse': array([0.05510479, 0.05513828, 0.05499408, 0.05582922, 0.05573016]),\n",
       " 'test_time': (0.3401031494140625,\n",
       "  0.31637144088745117,\n",
       "  0.3757472038269043,\n",
       "  0.22873568534851074,\n",
       "  0.2238445281982422)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# set train test as 75% 25%\n",
    "trainset, testset = train_test_split(data_purc, test_size=0.25)\n",
    "\n",
    "# train the model\n",
    "from surprise import SVD, accuracy\n",
    "algo = SVD(n_epochs=50, n_factors=50, verbose=True)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# validate the model accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "cross_validate(algo, data_purc, measures=['RMSE','MAE'], cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3a1ca",
   "metadata": {
    "id": "5ca3a1ca"
   },
   "source": [
    "Make predictions on the purchasing testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1952dc09",
   "metadata": {
    "id": "1952dc09"
   },
   "outputs": [],
   "source": [
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d9eb6",
   "metadata": {
    "id": "de7d9eb6"
   },
   "source": [
    "Model Evaluation on the purchasing testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9fdc84b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9fdc84b",
    "outputId": "b786d36a-4b28-42a9-a2bb-0bdf5cc4c5a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04557610670580696"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1q7WweUU70tX",
   "metadata": {
    "id": "1q7WweUU70tX"
   },
   "source": [
    "To recommend next game based on user inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lbY9-uKDxgtH",
   "metadata": {
    "id": "lbY9-uKDxgtH"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_all_predictions(predictions):\n",
    "  # first map the predictions to each user\n",
    "  top_n = defaultdict(list)\n",
    "  for uid, iid, true_r, est, _ in predictions:\n",
    "    top_n[uid].append((iid,est))\n",
    "\n",
    "  # then sort the predictions for each user\n",
    "  for uid, user_ratings in top_n.items():\n",
    "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "  return top_n\n",
    "\n",
    "all_pred_purc = get_all_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "OF8Mzitw-oek",
   "metadata": {
    "id": "OF8Mzitw-oek"
   },
   "outputs": [],
   "source": [
    "# filter userid where they have purchased at least 4 items\n",
    "new_all_pred_purc = dict(filter(lambda elem: len(elem[1]) >= 4 , all_pred_purc.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "_tXZCEOJ_iQb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tXZCEOJ_iQb",
    "outputId": "d58f7641-b9bd-4c91-f712-c41ca0cd2dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What did you buy? Crysis\n"
     ]
    }
   ],
   "source": [
    "# prompt user asking what did they buy previously and return 5 next recommendations (with ratings)\n",
    "game_name = input('What did you buy? ')\n",
    "\n",
    "# from users who purchased at least 4 items, sort according to ratings\n",
    "n = 4\n",
    "for uid, user_ratings in new_all_pred_purc.items():\n",
    "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    new_all_pred_purc[uid] = user_ratings[:n]\n",
    "\n",
    "# convert to DataFrame and transpose \n",
    "tmp = pd.DataFrame.from_dict(new_all_pred_purc)\n",
    "tmp_transpose = tmp.transpose()\n",
    "\n",
    "# define get_predictions function to find out the ratings of a certain user\n",
    "def get_predictions(user_id):\n",
    "    results = tmp_transpose.loc[user_id]\n",
    "    return results\n",
    "\n",
    "# now from the game that user input, find out which userid purchased the same game as his/hers\n",
    "similar_user = tmp_transpose.apply(lambda row: row.astype(str).str.contains(str(game_name)).any(), axis=1)\n",
    "similar_user_idx = similar_user[similar_user == True].index\n",
    "\n",
    "# find out highest rating of these users, store in a list\n",
    "s_user_item = []\n",
    "for i in similar_user_idx:\n",
    "  s_user_item.append(get_predictions(i))\n",
    "\n",
    "# the below changes to a list of tuples\n",
    "comb_tuple = []\n",
    "for sub in s_user_item:\n",
    "  for sub2 in sub:\n",
    "    comb_tuple.append(sub2)\n",
    "\n",
    "# define a function to sort the tuple according to the ratings, and only keep the highest rating for each game\n",
    "def sort_tuple(tup):\n",
    "  tup.sort(key = lambda x: x[1], reverse = True)\n",
    "  return tup\n",
    "comb_tuple_sorted = sort_tuple(comb_tuple)\n",
    "\n",
    "# now keep the highest rating only for each game, the rest will be removed\n",
    "from functools import reduce\n",
    "comb_tuple_nodup = reduce(lambda lu, i:i[0] in dict(lu).keys() and lu or lu+[i], comb_tuple_sorted, [])\n",
    "# high_tuple excludes the game user  has already purchased if the machine recommends again\n",
    "high_tuple = [x for x in comb_tuple_nodup if x[0] != game_name]\n",
    "\n",
    "# get the top 5 items\n",
    "top5_purc = high_tuple[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43993b",
   "metadata": {
    "id": "cc43993b"
   },
   "source": [
    "After preparing and training models for purchasing data, now let's repeat the same steps for playing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc19e719",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc19e719",
    "outputId": "c4071d73-7825-4ea6-c516-b0f0bdf7195c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# take the total sum of the hours played by each users, on each game\n",
    "ply['Total Hrs'] = ply.groupby('gametitle', sort=False)[\"value\"].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47711334",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47711334",
    "outputId": "949c0dbf-cd8b-4a00-de07-8c4e86f5be43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# scale the number of hours played to range from 1-5\n",
    "\n",
    "ori_hrs = ply['Total Hrs'].values.reshape(-1,1)\n",
    "scalar = MinMaxScaler(feature_range=(1,5))\n",
    "hrs_trans = scalar.fit_transform(ori_hrs)\n",
    "\n",
    "ply['hrs_trans'] = hrs_trans\n",
    "\n",
    "# roundup the ratings to the nearest integer\n",
    "ply['hrs_trans'] = ply.hrs_trans.apply(lambda n:roundup(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49609b19",
   "metadata": {
    "id": "49609b19"
   },
   "outputs": [],
   "source": [
    "# we revisit the surprise library\n",
    "reader = Reader(rating_scale = (1.0,5.0))\n",
    "data_ply = Dataset.load_from_df(ply[['userid','gametitle','hrs_trans']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea9aca5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea9aca5c",
    "outputId": "c1f897b9-83e7-44ea-9a33-4a3396ceb770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': (6.09004282951355,\n",
       "  6.196782350540161,\n",
       "  5.8806540966033936,\n",
       "  6.34937310218811,\n",
       "  5.9640421867370605),\n",
       " 'test_mae': array([0.04410841, 0.04460544, 0.04410527, 0.04309877, 0.04455485]),\n",
       " 'test_rmse': array([0.07183196, 0.07220988, 0.07151305, 0.07010363, 0.07194412]),\n",
       " 'test_time': (0.15743565559387207,\n",
       "  0.10882806777954102,\n",
       "  0.18155932426452637,\n",
       "  0.11167693138122559,\n",
       "  0.14271140098571777)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set train test as 75% 25%\n",
    "trainset, testset = train_test_split(data_ply, test_size=0.25)\n",
    "\n",
    "# train the model\n",
    "from surprise import SVD, accuracy\n",
    "algo = SVD(n_epochs=50, n_factors=50, verbose=True)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# validate the model accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "cross_validate(algo, data_ply, measures=['RMSE','MAE'], cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9784cfbb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9784cfbb",
    "outputId": "de9e0513-3d29-469a-d903-ca726a0c8380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05488868425450278"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions based on the trained model\n",
    "predictions_ply = algo.test(testset)\n",
    "\n",
    "from surprise import accuracy\n",
    "accuracy.rmse(predictions_ply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9hvC3xKUqKy-",
   "metadata": {
    "id": "9hvC3xKUqKy-"
   },
   "outputs": [],
   "source": [
    "# get all the predictions for hours of game played\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_all_predictions_ply(predictions):\n",
    "  # first map the predictions to each user\n",
    "  top_n = defaultdict(list)\n",
    "  for uid, iid, true_r, est, _ in predictions:\n",
    "    total_hrs_ply = ply.loc[ply['gametitle'] == iid, 'Total Hrs'].iloc[0]\n",
    "    top_n[uid].append((iid,est,total_hrs_ply))\n",
    "\n",
    "  # then sort the predictions for each user\n",
    "  for uid, user_ratings in top_n.items():\n",
    "    user_ratings.sort(key=lambda x: x[2], reverse=True)\n",
    "  return top_n\n",
    "\n",
    "all_pred_ply = get_all_predictions_ply(predictions_ply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea5581e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea5581e0",
    "outputId": "0bad939a-cb2b-40a8-bbb9-2439d094e1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks for purchasing Crysis !\n",
      "\n",
      "You may like these (popularity from 1(min) to 5(max):)\n",
      "Dota 2  (popularity: 4.8 )\n",
      "Team Fortress 2  (popularity: 2.9 )\n",
      "Half-Life 2  (popularity: 2.0 )\n",
      "Garry's Mod  (popularity: 2.0 )\n",
      "The Elder Scrolls V Skyrim  (popularity: 2.0 )\n",
      "\n",
      "You may consider these games which were played the most:\n",
      "Unturned  (Total Hours Played: 16096.4 )\n",
      "Portal 2  (Total Hours Played: 9117.1 )\n",
      "Dungeon Defenders  (Total Hours Played: 3816.2 )\n",
      "Divinity Original Sin  (Total Hours Played: 2380.1 )\n",
      "Mortal Kombat Komplete Edition  (Total Hours Played: 1324.3 )\n"
     ]
    }
   ],
   "source": [
    "# filter userid where they have played at least 4 games\n",
    "new_all_pred_ply = dict(filter(lambda elem: len(elem[1]) >= 4 , all_pred_ply.items()))\n",
    "\n",
    "# from users who played at least 4 games, sort according to hours played\n",
    "n = 4\n",
    "for uid, user_ratings in new_all_pred_ply.items():\n",
    "    user_ratings.sort(key=lambda x: x[2], reverse=True)\n",
    "    new_all_pred_ply[uid] = user_ratings[:n]\n",
    "\n",
    "# convert to DataFrame and transpose \n",
    "tmp_ply = pd.DataFrame.from_dict(new_all_pred_ply)\n",
    "tmp_transpose_ply = tmp_ply.transpose()\n",
    "\n",
    "# define get_predictions function to find out the ratings of a certain user\n",
    "def get_predictions(user_id):\n",
    "    results = tmp_transpose_ply.loc[user_id]\n",
    "    return results\n",
    "\n",
    "# now from the game that user input, find out which userid played the same game as his/hers\n",
    "similar_user_ply = tmp_transpose_ply.apply(lambda row: row.astype(str).str.contains(str(game_name)).any(), axis=1)\n",
    "similar_user_ply_idx = similar_user_ply[similar_user_ply == True].index\n",
    "\n",
    "# find out top N highest hours played of these users, store in a list\n",
    "s_user_item_ply = []\n",
    "for i in similar_user_ply_idx:\n",
    "  s_user_item_ply.append(get_predictions(i))\n",
    "\n",
    "# the below changes to a list of tuples\n",
    "comb_tuple_ply = []\n",
    "for sub in s_user_item_ply:\n",
    "  for sub2 in sub:\n",
    "    comb_tuple_ply.append(sub2)\n",
    "\n",
    "# define a function to sort the tuple according to the hours played\n",
    "def sort_tuple(tup):\n",
    "  tup.sort(key = lambda x: x[2], reverse = True)\n",
    "  return tup\n",
    "comb_tuple_ply_sorted = sort_tuple(comb_tuple_ply)\n",
    "\n",
    "# reduce tuple dimension from 3 to 2\n",
    "comb_tuple2_ply_sorted = []\n",
    "for tu in comb_tuple_ply_sorted:\n",
    "  comb_tuple2_ply_sorted.append((tu[0],tu[2]))\n",
    "\n",
    "# now keep the highest rating only for each game, the rest will be removed\n",
    "from functools import reduce\n",
    "comb_tuple_ply_nodup = reduce(lambda lu, i:i[0] in dict(lu).keys() and lu or lu+[i], comb_tuple2_ply_sorted, [])\n",
    "\n",
    "# high_tuple excludes the game user  has already played if the machine recommends again\n",
    "high_tuple_ply = [x for x in comb_tuple_ply_nodup if x[0] != game_name]\n",
    "\n",
    "# get the top 5 items\n",
    "top5_ply = high_tuple_ply[:5]\n",
    "\n",
    "# now print the outputs\n",
    "print('Thanks for purchasing', game_name, '!\\n')\n",
    "print('You may like these (popularity from 1(min) to 5(max):)')\n",
    "for x in top5_purc:\n",
    "  print(x[0], ' (popularity:', format(x[1],'.1f'), ')')\n",
    "\n",
    "# now print the outputs\n",
    "print('\\nYou may consider these games which were played the most:')\n",
    "for x in top5_ply:\n",
    "  ttl_hrs_ply = ply.loc[ply['gametitle'] == x[0], 'Total Hrs'].iloc[0]\n",
    "  print(x[0], ' (Total Hours Played:', format(ttl_hrs_ply,'.1f'), ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vDvGJLXqsCwH",
   "metadata": {
    "id": "vDvGJLXqsCwH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment2_svd_20210904.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
